# 13. Машинное обучение для текстов

### Цели проекта

- Используя набор данных с разметкой о токсичности, обучить модель классифицировать комментарии на позитивные и негативные.  
- По условию задачи необходимо построить модель со значением метрики качества *F1* не меньше `0.75`.  

### Задачи проекта

- Загрузить данные и выполнить их предварительную подготовку  
- Обучить модели с различными гиперпараметрами  
- Выбрать лучшую модель, проверить данные на тестовой выборке и сделать выводы  
- Решить задачу с помощью эмбеддингов, полученных от предобученной нейронной сети BERT, и сравнить полученную с их помощью метрику с остальными моделями  

### Итоги

- Полученные исходные данные с комментариями загружены, проанализированы и подготовлены для последующего обучения моделей.  
- Для моделей, которые не могут работать с текстовыми данными, корпуса слов обучающей и тестовой выборок были преобразованы в векторное представление TF-IDF с их трансформацией в разреженные матрицы.  
- Проведено обучение 3 видов моделей машинного обучения:  
	- LinearSVC (классификатора на основе опорных векторов)  
	- логистической регрессии LogisticRegression  
	- градиентного бустинга CatBoostClassifier  
- Лучшего значения по *F1* метрике, равного 0.`785`, из этих трёх перечисленных выше моделей позволил достичь градиентный бустинг CatBoostClassifier.  
- Стекинг моделей логистической регрессии и градиентного бустинга позволил повысить значение метрики *F1* до значения `0.808`.  
- Проведён анализ лучшей модели и результатов её работы по результатам которого выделены некоторые пути возможного улучшения качества работы моделей одним из которых является смещение порога классификации.  
- Опробовано специализированное решение для работы с текстовыми данными на основе эмбедингов BERT, которое позволило получить существенное увеличение метрики *F1* до значения `0.938`.  


### Используемый стек инструментов

- python
- pandas
- numpy
- sklearn
- nltk
- matplotlib
- seaborn
- torch
- BERT
